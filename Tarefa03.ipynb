{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 03 - Transfer Learning\n",
    "Nesta tarefa você irá carregar a SqueezeNet com pesos treinados no ImageNet e fará a transferênicia de aprendizado para um problema de classificação de raças de cachorro. \n",
    "\n",
    "------------\n",
    "## IMPORTANTE\n",
    "##### Verifique os pontos abaixo antes de começar a tarefa:\n",
    "- Faça download do dataset (arquivo `INF0618_Tarefa03_dogDataset.zip`) em `https://goo.gl/r44kAQ` e descomprima o .zip no mesmo diretório deste notebook;\n",
    "- Verifique se, após descomprimir .zip, há uma pasta `INF0618_Tarefa03_dogDataset` com as subpastas `train`, `test`, `val`;\n",
    "- Faça o download do modelo da squeezeNet (arquivo `squeezenet_weights_tf_dim_ordering_tf_kernels.h5` disponível no Moodle). Você também pode copiar o modelo dos arquivos da Aula 04 (apenas verifique o nome do arquivo).\n",
    "- Não há necessidade de alterar os códigos das sessões `Imports`, `Definição da SqueezeNet` e `Dataset`.\n",
    "-----------\n",
    "\n",
    "\n",
    "As tarefas são:\n",
    "\n",
    "**1) Definição do modelo [0.25 pts]**\n",
    "- Instancie o modelo base da SqueezeNet;\n",
    "- Escolha qual camada da rede que você utilizará como ponto de partida (..., fire8, fire9, drop9);\n",
    "- Escolha quais camadas terão os pesos atualizados e quais serão congeladas;\n",
    "- Adicione as camadas adicionais no topo da rede. Vocês estão livres em relação à quantidade e tipo de camadas após a SqueezeNet.\n",
    "\n",
    "**2) Treinamento [0.25 pts]**\n",
    "- Compile o seu modelo, definindo qual a loss e otimizador que serão utilizados;\n",
    "- Defina também número de batches e número de épocas;\n",
    "- Treine para obter a maior acurácia que você conseguirem;\n",
    "\n",
    "**3) Teste [0.25 pts]**\n",
    "- Avalie o conjunto de teste e reporte a loss e a acurácia normalizada;\n",
    "\n",
    "**4) Conclusões [0.25 pts]**\n",
    "- Escreva um parágrafo resumindo o que você fez, as dificuldades que encontrou, o que deu certo/errado e as suas conclusões desta atividade.\n",
    "\n",
    "------\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo base da SqueezeNet\n",
    "As funções abaixo criam o modelo da SqueezeNet e carregam os seus pesos treinados no ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "O dataset é composto por 83 classes (raças de cachorro) com 100 imagens de treinamento por classe. No conjunto de validação, há 73 imagens por classe. As imagens estão nomeadas no formato `xx_yyyy.jpg`, onde `xx` denota a classe (de 00 até 82) e `yyyy` é apenas um identificador da imagem.\n",
    "\n",
    "** IMPORTANTE NÃO ALTERAR O NOME/LOCAL DAS IMAGENS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDir = \"./INF0618_Tarefa03_dogDataset\"\n",
    "nbClasses = 83\n",
    "\n",
    "def getDatasetSize(split='train'):\n",
    "    if split not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(split + \" not recognized. Did you mean 'train', 'val' or 'test'?\")\n",
    "    splitDir = os.path.join(datasetDir, split)\n",
    "    \n",
    "    #Get all file names for that split\n",
    "    fileNames = [img for img in os.listdir(splitDir) if img[-3:] in ['jpg', 'png', 'jpeg']]\n",
    "    return len(fileNames)\n",
    "\n",
    "#Read our dataset in batches\n",
    "def loadDatasetInBatches(split=\"train\", batch_size=32):\n",
    "    if split not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(split + \" not recognized. Did you mean 'train', 'val' or 'test'?\")\n",
    "    splitDir = os.path.join(datasetDir, split)\n",
    "    \n",
    "    #Get all file names for that split\n",
    "    fileNames = [img for img in os.listdir(splitDir) if img[-3:] in ['jpg', 'png', 'jpeg']]\n",
    "\n",
    "    while True:\n",
    "        shuffledFileNames = sample(fileNames, len(fileNames)) #shuffle images in each epoch\n",
    "        imagePaths = [os.path.join(splitDir,img) for img in shuffledFileNames] #get image paths\n",
    "        \n",
    "        batch, labelList = [], []\n",
    "        nInBatch = 0\n",
    "        \n",
    "        #loop of one epoch\n",
    "        for idx in list(range(len(imagePaths))):\n",
    "                        img = img_to_array(load_img(imagePaths[idx], target_size=(227, 227)))\n",
    "                        img = img.astype('float32')\n",
    "                        img /= 255.0\n",
    "                    \n",
    "                        label = np_utils.to_categorical(getLabelFromImgName(shuffledFileNames[idx], split), nbClasses)\n",
    "                        \n",
    "                        ######### If you want to run with Data Augmentation, just uncomment here\n",
    "                        ##### you can add more transformations (see https://keras.io/preprocessing/image/)\n",
    "                        ### We apply a random transformation and add this image (instead of the original)\n",
    "                        ### to the batch...\n",
    "                        \n",
    "                        #dataAugmentator = ImageDataGenerator(horizontal_flip = True)\n",
    "                        #img = dataAugmentator.random_transform(img)\n",
    "                        \n",
    "                        \n",
    "                        batch.append(img)\n",
    "                        labelList.append(label)\n",
    "                        nInBatch += 1\n",
    "                        \n",
    "                        #if we already have one batch, yields it\n",
    "                        if nInBatch >= batch_size:\n",
    "                            yield np.array(batch), np.array(labelList)\n",
    "                            batch, labelList = [], []\n",
    "                            nInBatch = 0\n",
    "\n",
    "        #yield the remaining of the batch\n",
    "        if nInBatch > 0:\n",
    "            yield np.array(batch), np.array(labelList)\n",
    "\n",
    "\n",
    "def getLabelFromImgName(imgName, split):\n",
    "    return int(imgName.split(\"_\")[0])\n",
    "        \n",
    "    \n",
    "#plot the images from imgList\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "               \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img*255.0), interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "trainSetSize = getDatasetSize(\"train\")\n",
    "valSetSize = getDatasetSize(\"val\")\n",
    "testSetSize = getDatasetSize(\"test\")\n",
    "\n",
    "print(\"# images in Train set: \", trainSetSize)\n",
    "print(\"# images in Val set: \", valSetSize)\n",
    "print(\"# images in Test set: \", testSetSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, labels in loadDatasetInBatches(split='train', batch_size=5):\n",
    "    print(batch.shape, labels.shape)\n",
    "    plotImages(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o load do dados é feito...  \n",
    "O método que iremos utilizar para ler os dados é o `loadDatasetInBatches(split='train', batch_size=32)`. Ele é um generator (semelhante ao método que fazia a aumentação de dados na Aula 03), ou seja, ele gera um fluxo de batches e labels a partir do nosso dataset.\n",
    "\n",
    "**Argumentos**:\n",
    "- (string) **split**: pode ser `'train'`, `'val'` ou `'test'`. Se refere a qual conjunto de dados que iremos ler (treino, validação ou teste);\n",
    "- (int) **batch_size**: quantas imagens por batch;\n",
    "\n",
    "**Retorno**: \n",
    "- **batch**: retorna um array do numpy com as imagens carregadas e pre-processadas. **batch** tem dimensões (batch_size, 227, 227, 3), pois as imagens tem tamanho 227x227 e tem 3 canais (RGB);\n",
    "- **labels**: retorna um array do numpy com as labels já transformadas em one_hot_encode (array de 83 dimensões, com 1 na posição do índice da classe e 0 nas outras posições). **batch** tem dimensões (batch_size, 83);\n",
    "    \n",
    "Utilizando o argumento `split`, o método lê os nomes das imagens do diretório correto e as embaralha (para garantir que a cada época os batches sejam diferentes). Para cada época (um loop do `for` interno), o método irá carregar uma imagem por vez e irá gerar a sua label (obtendo a classe pelo próprio nome da imagem). Esta imagem/label será colocada em listas **batch/labelList**.\n",
    "\n",
    "Quando estas listas estiverem com **batch_size** elementos, teremos gerado um batch. O método dá um yield nessas duas e recomeça a construção de um novo batch. Quando o `for` terminar, iremos ter completado uma época. O `while True` apenas garante uma nova época seja iniciada. Quem controlará o fim do `while` vai ser o método que fará o fit, portanto não precisamos nos preocupar com isso.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "** -----> A tarefa começa aqui !!! Vocês não precisam modificar nada dos códigos acima!** \n",
    "\n",
    "# Definição do modelo [0.25 pts]\n",
    "\n",
    "- Instancie o modelo base da SqueezeNet;\n",
    "- Escolha qual camada da rede que você utilizará como ponto de partida (..., fire8, fire9, drop9);\n",
    "- Escolha quais camadas terão os pesos atualizados e quais serão congeladas;\n",
    "- Adicione as camadas adicionais no topo da rede. Vocês estão livres em relação à quantidade e tipo de camadas após a SqueezeNet.\n",
    "    - Lembrem-se que ao final da rede, precisamos de camadas de classificação:\n",
    "        - Conv2D + GlobalAveragePooling + SoftMax (aula 05)\n",
    "        - Flatten + Dense + SoftMax (aulas anteriores)\n",
    "    - Se acharem necessário, podem também adicionar outras camadas (Dropout, Conv2D, módulos Fire);\n",
    "    \n",
    "    \n",
    "**Não se esqueçam de:**\n",
    "- Definir novas camadas da mesma forma que fizemos na Aula 05 (utilizando o x = ...(x))\n",
    "- Ao final da célula, definir o modelo novo com o input da squeeze base e o output da última camada adicionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo base da squeezeNet \n",
    "#...\n",
    "\n",
    "# Escolher a camada que será o ponto de partida \n",
    "#...\n",
    "\n",
    "# Congelar (ou não) camadas\n",
    "#...\n",
    "\n",
    "# Adicionar novas camadas\n",
    "#...\n",
    "\n",
    "# Não se esqueça de definir o nome modelo, onde baseSqueezeNetModel \n",
    "# é o modelo base da Squeeze que vc definiu ali em cima\n",
    "# model = Model(baseSqueezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento [0.25 pts]\n",
    "\n",
    "- Compile o seu modelo, definindo qual a loss e otimizador que serão utilizados;\n",
    "- Defina também número de batches e número de épocas;\n",
    "- Treine para obter a maior acurácia que você conseguirem;\n",
    "\n",
    "\n",
    "No treinamento iremos utilizar o `fit_generator` (mesmo utilizado no Aula03 com Data Augmentation). Ele recebe um generator (que será fornecido pelo `loadDatasetInBatches`). Como o generator retorna um fluxo de batches/labels, o `fit_generator` não tem informação sobre o tamanho dataset. Por isso, precisamos informar o número de épocas (parâmetro `epochs`) e também quantos batches compõe uma época (parâmetro `steps_per_epoch`). Ao total, teremos 2 generators, um para o conjunto de treino e outro para o conjunto de teste.\n",
    "\n",
    "Para mais informações sobre o fit_generator e seus parâmetros, [acesse a documentação do Keras](https://keras.io/models/sequential/#fit_generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile o modelo\n",
    "# model.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir tamanho do batch e número de épocas\n",
    "batch_size = #\n",
    "epochs = #\n",
    "\n",
    "#Criação dos generators\n",
    "trainGenerator = loadDatasetInBatches(split='train', batch_size = batch_size)\n",
    "valGenerator = loadDatasetInBatches(split='val', batch_size = batch_size)\n",
    "\n",
    "#Fit nos dados\n",
    "model.fit_generator(trainGenerator, \n",
    "                    steps_per_epoch= int(trainSetSize / batch_size), \n",
    "                    epochs = epochs,\n",
    "                    validation_data = valGenerator,  \n",
    "                    validation_steps = int(valSetSize / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste [0.25 pts]\n",
    "O teste será feito da mesma forma, utilizando `loadDatasetInBatches` para o conjunto de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do generator p/ o conjunto de teste\n",
    "testGenerator = loadDatasetInBatches(split='test', batch_size=batch_size)\n",
    "\n",
    "#Teste\n",
    "metrics = model.evaluate_generator(testGenerator, \n",
    "                                   steps=int(testSetSize/batch_size), \n",
    "                                   verbose=1)\n",
    "\n",
    "print(\"Test Loss ---> \", metrics[0])\n",
    "print(\"Test Accuracy ---> \", metrics[1])    #Test is balanced, so Acc is normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões  [0.25 pts]\n",
    "Escrevam um parágrafo com as conclusões que vocês tiraram na tarefa. Comentem as dificuldades encontradas, as tentativas feitas, como foi o seu treinamento, apontando a motivação pelas decisões tomadas. Se o resultado ficou melhor/pior do que o que você esperava, o que você acha que pode ter acontecido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
